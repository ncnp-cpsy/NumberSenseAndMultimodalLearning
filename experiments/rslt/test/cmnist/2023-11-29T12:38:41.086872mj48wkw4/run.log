Expt: experiments/rslt/test/cmnist/2023-11-29T12:38:41.086872mj48wkw4
RunID: 2023-11-29T12:38:41.086872
Arguments: Namespace(K=20, batch_size=128, cuda=True, device='cuda', epochs=30, experiment='./rslt/test/cmnist', latent_dim=20, learn_prior=False, llik_scaling=0.0, logp=False, looser=False, model='Classifier_OSCN', no_analytics=False, no_cuda=False, num_hidden_layers=1, obj='cross', pre_trained='', pretrained_path='', print_freq=0, run_type='train', seed=4, use_conditional=False)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 16, 16]           1,568
              ReLU-2           [-1, 32, 16, 16]               0
            Conv2d-3             [-1, 64, 8, 8]          32,832
              ReLU-4             [-1, 64, 8, 8]               0
            Conv2d-5            [-1, 128, 4, 4]         131,200
              ReLU-6            [-1, 128, 4, 4]               0
            Conv2d-7              [-1, 8, 1, 1]          16,392
            Linear-8                    [-1, 9]              81
================================================================
Total params: 182,073
Trainable params: 182,073
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.22
Params size (MB): 0.69
Estimated Total Size (MB): 0.93
----------------------------------------------------------------
====> Epoch: 001 Train loss: 0.0015  took : 5.8614537715911865
====> Epoch: 002 Train loss: 0.0000  took : 5.27944278717041
====> Epoch: 003 Train loss: 0.0000  took : 6.162742853164673
====> Epoch: 004 Train loss: 0.0000  took : 4.795398950576782
====> Epoch: 005 Train loss: 0.0000  took : 4.975661516189575
====> Epoch: 006 Train loss: 0.0000  took : 5.24573278427124
====> Epoch: 007 Train loss: 0.0000  took : 4.93500018119812
====> Epoch: 008 Train loss: 0.0000  took : 5.182616233825684
====> Epoch: 009 Train loss: 0.0000  took : 5.1481711864471436
====> Epoch: 010 Train loss: 0.0000  took : 5.0597312450408936
====> Epoch: 011 Train loss: 0.0000  took : 4.973295211791992
====> Epoch: 012 Train loss: 0.0000  took : 5.076290607452393
====> Epoch: 013 Train loss: 0.0000  took : 4.807479381561279
====> Epoch: 014 Train loss: 0.0000  took : 5.248781681060791
====> Epoch: 015 Train loss: 0.0000  took : 5.0536723136901855
====> Epoch: 016 Train loss: 0.0000  took : 5.203871488571167
====> Epoch: 017 Train loss: 0.0000  took : 5.27839732170105
====> Epoch: 018 Train loss: 0.0000  took : 4.880058526992798
====> Epoch: 019 Train loss: 0.0000  took : 4.9839489459991455
====> Epoch: 020 Train loss: 0.0000  took : 2.696078062057495
====> Epoch: 021 Train loss: 0.0000  took : 5.072368383407593
====> Epoch: 022 Train loss: 0.0000  took : 5.044372797012329
====> Epoch: 023 Train loss: 0.0000  took : 5.163543939590454
====> Epoch: 024 Train loss: 0.0000  took : 5.183195114135742
====> Epoch: 025 Train loss: 0.0000  took : 5.207195281982422
====> Epoch: 026 Train loss: 0.0000  took : 6.155052423477173
====> Epoch: 027 Train loss: 0.0000  took : 5.137454509735107
====> Epoch: 028 Train loss: 0.0000  took : 4.922802925109863
====> Epoch: 029 Train loss: 0.0000  took : 5.087426662445068
====> Epoch: 030 Train loss: 0.0000  took : 5.007208585739136
====> [MM-VAE] Time: 160.804s or 00:02:40
