Expt: experiments/rslt/test/cmnist/2023-11-29T16:55:46.6162587y6zyyd4
RunID: 2023-11-29T16:55:46.616258
Arguments: Namespace(K=20, batch_size=128, cuda=True, device='cuda', epochs=30, experiment='./rslt/test/cmnist', latent_dim=20, learn_prior=False, llik_scaling=0.0, logp=False, looser=False, model='Classifier_OSCN', no_analytics=False, no_cuda=False, num_hidden_layers=1, obj='cross', pre_trained='', pretrained_path='', print_freq=0, run_type='train', seed=4, use_conditional=False)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 16, 16]           1,568
              ReLU-2           [-1, 32, 16, 16]               0
            Conv2d-3             [-1, 64, 8, 8]          32,832
              ReLU-4             [-1, 64, 8, 8]               0
            Conv2d-5            [-1, 128, 4, 4]         131,200
              ReLU-6            [-1, 128, 4, 4]               0
            Conv2d-7              [-1, 8, 1, 1]          16,392
            Linear-8                    [-1, 9]              81
================================================================
Total params: 182,073
Trainable params: 182,073
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.22
Params size (MB): 0.69
Estimated Total Size (MB): 0.93
----------------------------------------------------------------
====> Epoch: 001 Train loss: 0.0015  took : 5.058154344558716
====> Epoch: 002 Train loss: 0.0000  took : 5.324395656585693
====> Epoch: 003 Train loss: 0.0000  took : 5.280874729156494
====> Epoch: 004 Train loss: 0.0000  took : 5.050638914108276
====> Epoch: 005 Train loss: 0.0000  took : 5.146170377731323
====> Epoch: 006 Train loss: 0.0000  took : 2.6802408695220947
====> Epoch: 007 Train loss: 0.0000  took : 2.7772624492645264
====> Epoch: 008 Train loss: 0.0000  took : 6.061204195022583
====> Epoch: 009 Train loss: 0.0000  took : 5.1406731605529785
====> Epoch: 010 Train loss: 0.0000  took : 5.21677827835083
====> Epoch: 011 Train loss: 0.0000  took : 5.229094982147217
====> Epoch: 012 Train loss: 0.0000  took : 5.107966661453247
====> Epoch: 013 Train loss: 0.0000  took : 5.249632358551025
====> Epoch: 014 Train loss: 0.0000  took : 5.142075777053833
====> Epoch: 015 Train loss: 0.0000  took : 5.991197824478149
====> Epoch: 016 Train loss: 0.0000  took : 5.148787975311279
====> Epoch: 017 Train loss: 0.0000  took : 5.10787034034729
====> Epoch: 018 Train loss: 0.0000  took : 5.181642770767212
====> Epoch: 019 Train loss: 0.0000  took : 5.14595890045166
====> Epoch: 020 Train loss: 0.0000  took : 5.051789045333862
====> Epoch: 021 Train loss: 0.0000  took : 5.075330018997192
====> Epoch: 022 Train loss: 0.0000  took : 5.0992937088012695
====> Epoch: 023 Train loss: 0.0000  took : 5.06676459312439
====> Epoch: 024 Train loss: 0.0000  took : 5.793211936950684
====> Epoch: 025 Train loss: 0.0000  took : 5.083773851394653
====> Epoch: 026 Train loss: 0.0000  took : 5.12438702583313
====> Epoch: 027 Train loss: 0.0000  took : 5.253482341766357
====> Epoch: 028 Train loss: 0.0000  took : 5.128049612045288
====> Epoch: 029 Train loss: 0.0000  took : 5.157074213027954
====> Epoch: 030 Train loss: 0.0000  took : 5.159341812133789
====> [MM-VAE] Time: 159.894s or 00:02:39
